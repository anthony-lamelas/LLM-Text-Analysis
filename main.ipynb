{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pip Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain_pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytesseract in c:\\users\\antho\\anaconda3\\envs\\airscope\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: pdf2image in c:\\users\\antho\\anaconda3\\envs\\airscope\\lib\\site-packages (1.17.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\antho\\anaconda3\\envs\\airscope\\lib\\site-packages (from pytesseract) (24.2)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in c:\\users\\antho\\anaconda3\\envs\\airscope\\lib\\site-packages (from pytesseract) (11.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytesseract pdf2image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import os\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "import langchain\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings, OpenAI\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing pdf loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDFLoader:\n",
    "    def __init__(self, pdf_path):\n",
    "        self.pdf_path = pdf_path\n",
    "\n",
    "    def extract_text(self):\n",
    "        doc = fitz.open(self.pdf_path)\n",
    "        text = \"\"\n",
    "\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "        return text\n",
    "    \n",
    "# if __name__ == '__main__':\n",
    "#     loader = PDFLoader(\"pdfs/India-AQLI.pdf\")\n",
    "#     text = loader.extract_text()\n",
    "#     print(text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "class EmbeddingGenerator:\n",
    "    def __init__(self):\n",
    "        openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        if not openai_api_key:\n",
    "            raise ValueError(\"OPENAI_API_KEY not set\")\n",
    "        \n",
    "    # split into chunks by tokens\n",
    "    def chunk_text_by_tokens(self, text, chunk_size, encoding_name=\"cl100k_base\"):\n",
    "        encoding = tiktoken.get_encoding(encoding_name)\n",
    "        tokens = encoding.encode(text)\n",
    "        return [encoding.decode(tokens[i:i + chunk_size]) for i in range(0, len(tokens), chunk_size)]\n",
    "\n",
    "    # generate embeddings for each chunk and return list of embeddings\n",
    "    def generate_embeddings(self, chunks):\n",
    "        embeddings = []\n",
    "        for chunk in chunks:\n",
    "            response = openai.embeddings.create(\n",
    "                input=chunk,\n",
    "                model=\"text-embedding-ada-002\"\n",
    "            )\n",
    "            embeddings.append(response.data[0].embedding)\n",
    "        return embeddings\n",
    "    \n",
    "    # split text into chunks and generate embeddings\n",
    "    def process_text(self, text, chunk_size=1000):\n",
    "        if not isinstance(text, str) or len(text) == 0:\n",
    "            raise ValueError(\"Input text must be a non-empty string\")\n",
    "        chunks = self.chunk_text_by_tokens(text, chunk_size)\n",
    "        embeddings = self.generate_embeddings(chunks)\n",
    "        return chunks, embeddings\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     generator = EmbeddingGenerator()\n",
    "#     chunks, embeddings = generator.process_text(text, chunk_size=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PineconeStore:\n",
    "\n",
    "    def __init__(self, environmeent=\"us-east-1\"):\n",
    "        pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "        if not pinecone_api_key:\n",
    "            raise ValueError(\"PINECONE_API_KEY not set\")\n",
    "        \n",
    "        # pinecone instance\n",
    "        self.pc = Pinecone(ap_key=pinecone_api_key)\n",
    "        self.index_name = \"pdf-vector-store-pollution\"\n",
    "\n",
    "        if self.index_name not in self.pc.list_indexes().names():\n",
    "            self.pc.create_index(\n",
    "                name=self.index_name,\n",
    "                dimension=1536,\n",
    "                metric='cosine',\n",
    "                spec=ServerlessSpec(cloud='aws', region='us-east-1')\n",
    "    )\n",
    "    \n",
    "    def save_vectors(self, vectors, metadata, chunks):\n",
    "        index = self.pc.Index(self.index_name)\n",
    "\n",
    "        # save each embedding with unique metadata\n",
    "        for i, vector in enumerate(vectors):\n",
    "            vector_id = f\"{metadata['id']}_chunk_{i}\" # uniqe id\n",
    "            chunk_metadata = {\n",
    "                \"id\": vector_id,\n",
    "                \"source\" : metadata[\"source\"],\n",
    "                \"chunk\" : i,\n",
    "                \"text\": chunks[i]\n",
    "            }\n",
    "\n",
    "            index.upsert(vectors=[(vector_id, vector, chunk_metadata)])\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     vector_store = PineconeStore()\n",
    "#     vector_store.save_vectors(embeddings, {\"id\": \"doc_1\", \"source\": \"example.pdf\"}, chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PineconeRetriever:\n",
    "    def __init__(self, pinecone_api_key, openai_api_key):\n",
    "\n",
    "        # pinecone connection\n",
    "        self.pc = Pinecone(api_key=pinecone_api_key)\n",
    "        self.index_name = \"pdf-vector-store-pollution\"\n",
    "        self.index = self.pc.Index(self.index_name)\n",
    "\n",
    "        # openAi model and embeddings\n",
    "        self.embedding_model = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "        self.llm = OpenAI(temperature=0, api_key=openai_api_key)\n",
    "\n",
    "        # create the Pinecone vector store\n",
    "        self.vector_store = PineconeVectorStore(index=self.index, embedding=self.embedding_model, text_key=\"text\")\n",
    "        self.retriever = self.vector_store.as_retriever()\n",
    "\n",
    "        # create the RetrievalQA chain\n",
    "        self.qa_chain = RetrievalQA.from_chain_type(llm=self.llm, chain_type=\"stuff\", retriever=self.retriever)\n",
    "\n",
    "    def query(self, query_text):\n",
    "        # execute the QA chain with the input query\n",
    "        response = self.qa_chain.invoke({\"query\": query_text})\n",
    "        return response['result']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: AQLI-2024-Report_English.pdf\n",
      "Processing: Bangladesh-FactSheet-2023_Final.pdf\n",
      "Processing: Central-and-West-Africa-2022.pdf\n",
      "Processing: China-FactSheet_2024.pdf\n",
      "Processing: DRC-FactSheet_2024.pdf\n",
      "Processing: India-FactSheet_2024.pdf\n",
      "Processing: List_of_countries_by_air_pollution.pdf\n",
      "Processing: Nepal-FactSheet_2024.pdf\n",
      "Processing: Pakistan-FactSheet_2024.pdf\n",
      "Processing: Qatar-FactSheet_2024-1.pdf\n",
      "Processing: US-FactSheet_2024.pdf\n",
      " According to recent data, China's air pollution levels have been decreasing since 2014 due to strict pollution control measures. However, the country still has a long way to go as 99.9% of its population lives in areas where the annual average particulate pollution level exceeds the WHO guideline. Air pollution is the third highest risk factor for reduced life expectancy in China, and if pollution levels were reduced to meet the WHO guideline, the average Chinese citizen could expect to live 2.3 years longer. Some regions, such as the Beijing-Tianjin-Hebei region, are more heavily polluted and residents there could gain up to 3.4 additional years of life expectancy if pollution levels were reduced to meet the WHO guideline. However, there are still 54 prefectures in China that do not meet even the national pollution standard, and reducing pollution in these areas could add 3.5 years to the life expectancy of 318.1 million residents. While there have been improvements in reducing pollution, there are still areas in China where pollution levels have increased since 2013.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    folder_path = \"./pdfs\"\n",
    "    generator = EmbeddingGenerator()\n",
    "    vector_store = PineconeStore()\n",
    "\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(folder_path, file)\n",
    "            print(f\"Processing: {file}\")\n",
    "\n",
    "            loader = PDFLoader(pdf_path)\n",
    "            text = loader.extract_text()\n",
    "\n",
    "            chunks, embeddings = generator.process_text(text, chunk_size=800)\n",
    "            metadata = {\"id\": file.split(\".\")[0], \"source\": file}\n",
    "            vector_store.save_vectors(embeddings, metadata, chunks)\n",
    "\n",
    "    pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "    retriever = PineconeRetriever(pinecone_api_key=pinecone_api_key, openai_api_key=openai_api_key)\n",
    "    result = retriever.query(\"Tell me about the air pollution in China || Make the response a maximum of 4 sentences.\")\n",
    "    print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AirScope",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
